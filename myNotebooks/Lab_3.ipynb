{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3e6e6e",
   "metadata": {},
   "source": [
    "## **Laboratory Task 3**\n",
    "#### **DS Elective 4 - Deep Learning**\n",
    "\n",
    "**Name:** John Vincent Gamali <br>\n",
    "**Year & Section:** DS4A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412c34f",
   "metadata": {},
   "source": [
    "## Forward and Backward Propagation in Python <br>\n",
    "In this activity, we extend the feedforward neural network by adding **backpropagation**. \n",
    "We first perform a forward pass to compute the weighted sums, apply the **ReLU activation function**, and generate the prediction. \n",
    "Then, we calculate the error using **Mean Squared Error (MSE)** and apply **backpropagation** to compute gradients with respect to the weights and biases. \n",
    "Finally, we update the parameters using **gradient descent** with the specified learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a374c3b",
   "metadata": {},
   "source": [
    "Here is the given problem setup:\n",
    "\n",
    "<img src=\"https://i.ibb.co/TM29FCJJ/Screenshot-2025-09-13-at-1-31-33-PM.png\" width=\"1200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407c47e",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e726bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4ddb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and target\n",
    "\n",
    "x = np.array([1, 0, 1])   # input vector\n",
    "y = np.array([1])         # target output\n",
    "lr = 0.001                # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e08eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and biases (from Task 2)\n",
    "# Hidden layer weights\n",
    "\n",
    "W_hidden = np.array([\n",
    "    [0.2, -0.3],   # weights for input x1\n",
    "    [0.4,  0.1],   # weights for input x2\n",
    "    [-0.5, 0.2]    # weights for input x3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cc98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biases for hidden neurons\n",
    "b_hidden = np.array([-0.4, 0.2])\n",
    "\n",
    "# Output layer weights\n",
    "W_output = np.array([[-0.3], [-0.2]])\n",
    "\n",
    "# Bias for output neuron\n",
    "b_output = np.array([0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f256d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return np.where(z > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381c2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "\n",
    "# Hidden layer computation\n",
    "Z_hidden = np.dot(x, W_hidden) + b_hidden  \n",
    "H = relu(Z_hidden)                    \n",
    "\n",
    "# Output layer computation\n",
    "Z_output = np.dot(H, W_output) + b_output\n",
    "y_hat = relu(Z_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b46c18",
   "metadata": {},
   "source": [
    "### FeedForward Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e51586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass:\n",
      "Z_hidden = [-0.7  0.1]\n",
      "H (hidden activations) = [0.  0.1]\n",
      "Z_output = [0.08]\n",
      "y_hat (prediction) = [0.08]\n"
     ]
    }
   ],
   "source": [
    "print(\"Forward Pass:\")\n",
    "print(\"Z_hidden =\", Z_hidden)\n",
    "print(\"H (hidden activations) =\", H)\n",
    "print(\"Z_output =\", Z_output)\n",
    "print(\"y_hat (prediction) =\", y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053996fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.8464\n"
     ]
    }
   ],
   "source": [
    "# Compute loss (MSE)\n",
    "loss = np.mean((y - y_hat) ** 2)\n",
    "print(\"Loss =\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06371b",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fcd1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "# Derivative of loss w.r.t y_hat (MSE derivative)\n",
    "dL_dyhat = 2 * (y_hat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative through ReLU at output\n",
    "dyhat_dZout = relu_derivative(Z_output)\n",
    "dL_dZout = dL_dyhat * dyhat_dZout\n",
    "\n",
    "# Gradients for output weights and bias\n",
    "dL_dWout = H.reshape(-1,1) @ dL_dZout.reshape(1,-1)\n",
    "dL_dbout = dL_dZout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "212bf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients for output weights and bias\n",
    "dL_dWout = H.reshape(-1,1) @ dL_dZout.reshape(1,-1)\n",
    "dL_dbout = dL_dZout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a21c617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop to hidden layer\n",
    "dL_dH = dL_dZout @ W_output.T\n",
    "dH_dZhidden = relu_derivative(Z_hidden)\n",
    "dL_dZhidden = dL_dH * dH_dZhidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833bd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients for hidden weights and biases\n",
    "dL_dWhidden = x.reshape(-1,1) @ dL_dZhidden.reshape(1,-1)\n",
    "dL_dbhidden = dL_dZhidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814342e9",
   "metadata": {},
   "source": [
    "### Backward Propogation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ca9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward Pass:\n",
      "dL_dWout = \n",
      " [[ 0.   ]\n",
      " [-0.184]]\n",
      "dL_dbout = \n",
      " [-1.84]\n",
      "dL_dWhidden = \n",
      " [[0.         0.36766144]\n",
      " [0.         0.        ]\n",
      " [0.         0.36766144]]\n",
      "dL_dbhidden = \n",
      " [0.         0.36766144]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBackward Pass:\")\n",
    "print(\"dL_dWout =\", \"\\n\",dL_dWout)\n",
    "print(\"dL_dbout =\", \"\\n\", dL_dbout)\n",
    "print(\"dL_dWhidden =\",\"\\n\", dL_dWhidden)\n",
    "print(\"dL_dbhidden =\",\"\\n\", dL_dbhidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1a5a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "W_output -= lr * dL_dWout\n",
    "b_output -= lr * dL_dbout\n",
    "W_hidden -= lr * dL_dWhidden\n",
    "b_hidden -= lr * dL_dbhidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273bcc77",
   "metadata": {},
   "source": [
    "#### Final Results (Updated Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42554933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Parameters:\n",
      "W_hidden = \n",
      " [[ 0.2      -0.300368]\n",
      " [ 0.4       0.1     ]\n",
      " [-0.5       0.199632]]\n",
      "b_hidden = \n",
      " [-0.4       0.199632]\n",
      "W_output = \n",
      " [[-0.3     ]\n",
      " [-0.199816]]\n",
      "b_output = \n",
      " [0.10184]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdated Parameters:\")\n",
    "print(\"W_hidden =\",\"\\n\", W_hidden)\n",
    "print(\"b_hidden =\",\"\\n\", b_hidden)\n",
    "print(\"W_output =\", \"\\n\",W_output)\n",
    "print(\"b_output =\",\"\\n\", b_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73468ab0",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "In this activity, we explored forward and backward propagation in a feedforward neural network. We computed weighted sums, applied ReLU, and generated predictions, then measured error using Mean Squared Error (MSE). Through backpropagation and gradient descent, we updated parameters, demonstrating how a neural network learns by making predictions, evaluating errors, and adjusting to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4341cb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jbook-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
